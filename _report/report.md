## 计算方法
总分 = 100 - 场景1的距离 - 场景2的距离 - 场景3的距离
场景i的得分 = 100 - 场景1的距离
# 提交记录
| 提交id | 提交时间 | 总分 |model1方法 | 1得分 | 2得分 |  model1总结  | model2方法 |  3得分 | model2总结 |
|  ----  |  ----  |  ----  | ----  | ----  | ----  | ----  | ---- |---- |---- |
| 1 | | 32.89986638 |官方baseline | 98.79622250 | 49.26791637 | | 用的model1 | 84.83572752 | |
| 2 | | 82.12482187987 | model1置零 | 98.66551103312s | 98.62358332648 | 只用4个通道对场景1的效果影响不大，但是对场景2十分友好| 同上 | 同上| |
| 3 | | 81.81949819408 | 同上 |同上 | 同上 | | 只用1000个标签样本 |  84.53040383447 | 还不如直接用model1 |
| 4 | | 63.62159753349 | 20epoch-->100epoch |85.49242591707 | 86.15884952062 |  100个epoch，model1好像过拟合了，远不如之前20个epoch| 20epoch-->100epoch,最简单的半监督 |   91.97032209580 | 最简单的半监督得到的model2比之前还是有提升的 |
| 5 | 2022/08/07 23:48 | | | | | | 100epoch-->20epoch | 84.94623435439 | 4里面model2训练100epoch比20个epoch效果好，20个epoch欠拟合 |
| 6 | 2022/08/08 16:59 | | | | | | 花时间设计的半监督训练方式  | 91.52268251519 | 比最傻逼的半监督低了0.4个百分点，但是这次所有的训练都只有50个epoch |
| 7 | 2022/08/08 18:29 | 88.49257067111 | 在2的基础上加weight_decay | 98.49197300421 | 98.47791515170 | 加了weight_decay之后略微降了0.2左右 | 同上 | 同上 | 同上 |
| 8 | 2022/08/08 19:30 | | 在7的基础上，20epoch改为40epoch | 98.85236625224 | 98.84850910502 | 可以，是目前最强了 |  |  |  |
| 9 | 2022/08/08 23:16 | | 在7的基础上，L1loss改为MSEloss, 100epoch(重写了model1的网络，按道理是没有变化的) | 99.53934768497 | 99.53123079894 | 目前最强了，继续训或许可以更强 |  |  |  |
| 10-1 | 2022/08/09 00:55 | | 100epoch改为200epoch | 99.61251968129 | 99.60585838940 | 又强了0.1左右 |  |  |  |
| 10-2 | 2022/08/09 09:28 | | 200epoch改为500epoch | 99.68704509416 | 99.67430117920 | 又强了0.1左右,继续训，或许还可以增强 |  |  |  |
| 10-3 | 2022/08/09 13:30 | 92.56184395481 | 500epoch改为1000epoch | 99.71858824222 | 99.71303769030scenario | 又强了0.03左右,继续训，或许还可以增强 |  在4的基础上，傻逼版半监督，打乱数据顺序，1000个epoch |93.13021802229 | 提升了一个百分点 |
| 11 | | | 在10-3的基础上打乱数据顺序，10000个epoch，只训到3000多个，最后一次保存是2500epoch | 99.75241118782 | 99.73356698664 | 又好了一些 |   |  |  |
| 12 | 2022/08/09 23:11 | | 限制预测在范围内 |